{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08dc2f24-7450-4ba8-a6f4-00cbe9813e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['48_3.png', '48_2.png', '48_0.png', '48_1.png', '48_5.png', '48_4.png', '48_6.png', '48_7.png', '48_8.png']\n",
      "48_3.png 1_:104 , 2_:100,3_:172 , 4_:26, 5_:104 \n",
      "\n",
      "48_2.png 1_:102 , 2_:101,3_:175 , 4_:26, 5_:104 \n",
      "\n",
      "48_0.png 1_:109 , 2_:99,3_:173 , 4_:12, 5_:114 \n",
      "\n",
      "48_1.png 1_:111 , 2_:97,3_:174 , 4_:16, 5_:114 \n",
      "\n",
      "48_5.png 1_:106 , 2_:101,3_:177 , 4_:136, 5_:97 \n",
      "\n",
      "48_4.png 1_:105 , 2_:102,3_:133 , 4_:154, 5_:100 \n",
      "\n",
      "48_6.png 1_:104 , 2_:103,3_:3 , 4_:157, 5_:101 \n",
      "\n",
      "48_7.png 1_:79 , 2_:119,3_:10 , 4_:177, 5_:37 \n",
      "\n",
      "48_8.png 1_:76 , 2_:121,3_:10 , 4_:176, 5_:37 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# from imutils.video import WebcamVideoStream\n",
    "# import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import threading\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "# from imutils.video import FPS\n",
    "mp.solutions.drawing_utils._VISIBILITY_THRESHOLD = 0.01\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "landmark_lb = [ \"Elbow(L)\", \"Elbow(R)\", \"Shoulder(L)\", \"Shoulder(R)\",  \"Hip(L)\", \"Hip(R)\", \"Knee(L)\", \"Knee(R)\", \"FOOT(L)\", \"FOOT(R)\", \"NECK(H)\", \"NECK(V)\"]\n",
    "\n",
    "z_scale_factor = np.array([ 1, \n",
    "                           1, 1, 1, 1, 1, \n",
    "                           1, 1, 1, 1, 1, \n",
    "                           0.2, 0.2, 0.2, 0.2, 0.2, \n",
    "                           0.2, 1, 1, 1, 1, \n",
    "                           1, 1, 0.5, 0.5, 0.5, \n",
    "                           0.5, 0.5, 0.5, 1, 1, \n",
    "                           0.5, 0.5])\n",
    "\n",
    "def get_angle(a, b, c):\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    ba[2] = 0\n",
    "    bc[2] = 0\n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    \n",
    "    return np.degrees(angle)\n",
    "\n",
    "def get_stand(a, b):\n",
    "    ba = a - b\n",
    "    y_differ = ba[1]\n",
    "    z_differ = ba[2]\n",
    "    return [y_differ,z_differ]\n",
    "\n",
    "def get_gradient(a,b):\n",
    "    c = [b[0],a[1],a[2]]\n",
    "    \n",
    "    ba = b - a\n",
    "    ac = c - a\n",
    "  \n",
    "    ba[2] = 0\n",
    "    ac[2] = 0\n",
    "    #print('ba',ba,'\\nac',ac)\n",
    "    cosine_angle = np.dot(ba, ac) / (np.linalg.norm(ba) * np.linalg.norm(ac))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    \n",
    "    return np.degrees(angle)\n",
    "    \n",
    "\n",
    "def get_joint_angle(data):\n",
    "    #angle 입력하는 곳\n",
    "    joints = [[11,23,24],[12,24,23],[15,13,11],[16,14,12],[11,0,12]\n",
    "]\n",
    "  \n",
    "    stand = [[23,24],[7,8]]\n",
    "    \n",
    "    return np.array([ get_angle( *data[j, :3]) if len(j) == 3 else get_gradient( *data[j, :3]) for j in joints]),np.array([ get_stand( *data[j, :3]) for j in stand])\n",
    "\n",
    "\n",
    "def angle_differ(arr):\n",
    "    angle_arr = []\n",
    "    for i in range(len(arr)-1):\n",
    "        appends = np.abs(arr[i+1] - arr[i])\n",
    "        appends = appends.tolist()\n",
    "        angle_arr.append(appends)\n",
    "    angle_arr = np.array(angle_arr)\n",
    "    return angle_arr\n",
    "#threshold csv 파일 값 읽어오기\n",
    "    \n",
    "\n",
    "# 디스플레이 부분\n",
    "\n",
    "\n",
    "# Display function\n",
    "# ================\n",
    "def view():\n",
    "    #사진 넣을 경우\n",
    "    #cap = cv2.imread('./pic/12.jpg', cv2.IMREAD_COLOR)\n",
    "    #비디오 넣을 경우\n",
    "    #cap = cv2.VideoCapture('./33.mp4')\n",
    "    \n",
    "    lo = '../48/'\n",
    "    data = os.listdir(lo)\n",
    "    print(data)\n",
    "    \n",
    "    coords = np.zeros((1, 38,4))\n",
    "\n",
    "    cnt = 0\n",
    "    cur_id = 0\n",
    "    create = None\n",
    "    \n",
    "    #i = 0\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        enable_segmentation=False) as pose:\n",
    "    \n",
    "        \n",
    "        for img in data:\n",
    "            #비디오\n",
    "            #_,frame = cap.read()\n",
    "            #사진\n",
    "            cap = cv2.imread(lo+img, cv2.IMREAD_COLOR)\n",
    "            frame = cap\n",
    "\n",
    "            image_height, image_width, _ = frame.shape\n",
    "            results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            if results.pose_landmarks is None:\n",
    "                print('nope')\n",
    "                continue\n",
    "\n",
    "\n",
    "            cur_coord = np.array([(results.pose_landmarks.landmark[i].x, \n",
    "                              results.pose_landmarks.landmark[i].y, \n",
    "                              results.pose_landmarks.landmark[i].z, \n",
    "                              results.pose_landmarks.landmark[i].visibility) for i in range(33)])#if results.pose_landmarks.landmark[i].visibility > 0.2 else (0,0,0,0) for i in range(33) ])\n",
    "\n",
    "\n",
    "            #cur_coord[:,2] = cur_coord[:,2] *0\n",
    "\n",
    "\n",
    "            #cur_coord[:, 2] = cur_coord[:, 2] * z_scale_factor\n",
    "\n",
    "            cur_coord = np.append( cur_coord, np.reshape(np.append(cur_coord[31:32, :2], cur_coord[27:28, 2:], axis=0), (-1,4)), axis= 0)\n",
    "            cur_coord = np.append( cur_coord, np.reshape(np.append(cur_coord[32:33, :2], cur_coord[28:29, 2:], axis=0), (-1,4)), axis= 0)\n",
    "            cur_coord = np.append( cur_coord, np.reshape(np.append(cur_coord[7:8, :2], cur_coord[8:9, 2:], axis=0), (-1,4)), axis= 0)\n",
    "            cur_coord = np.append( cur_coord, np.reshape([ cur_coord[8, 0], cur_coord[7, 1], cur_coord[8, 2], cur_coord[8, 3]], (-1,4)), axis= 0)\n",
    "            cur_coord = np.append( cur_coord, np.reshape(np.append(cur_coord[0:1, :2], cur_coord[8:9, 2:], axis=0), (-1,4)), axis= 0)\n",
    "\n",
    "\n",
    "            coords = np.append(coords[-2:], np.reshape(cur_coord, (-1,38,4)), axis=0)\n",
    "\n",
    "            coord = np.median(coords, axis =0 )\n",
    "\n",
    "            input_angles, input_stands = get_joint_angle(coord) \n",
    "            \n",
    "            #print('입력한 조인트 각도',input_angles)\n",
    "            #print('잘 서있는지 확인 하는 각도',input_stands)\n",
    "\n",
    "            #이미지에 텍스트 표기하는 부분\n",
    "            text = \"1_:{:.0f} , 2_:{:.0f},3_:{:.0f} , 4_:{:.0f}, 5_:{:.0f}\".format(input_angles[0],input_angles[1],input_angles[2],input_angles[3],input_angles[4]) #,input_stands[0][0])#,input_stands[1][0])\n",
    "            print(img,text,'\\n')\n",
    "            cv2.putText(frame, text, (10, 40), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,1, (255, 255, 255), 1)\n",
    "            \n",
    "            #cv2.imshow('frame', frame)\n",
    "            cv2.imwrite(str(img),frame)\n",
    "\n",
    "#             if create is None:\n",
    "#                 fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#                 create = cv2.VideoWriter(\"output.avi\", fourcc, 30, (640, 480), True)\n",
    "\n",
    "#             create.write(frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "                \n",
    "            i=+1\n",
    "            time.sleep(1)\n",
    "                \n",
    "# ================\n",
    "view()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef77fe5-e447-4982-b155-b69ce4440286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153778d7-283d-44a7-90bd-881666265597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir",
   "language": "python",
   "name": "vir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
